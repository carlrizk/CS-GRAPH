{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "from twitch_utils import (\n",
    "    load_features,\n",
    "    remove_features,\n",
    "    load_edges,\n",
    "    create_graph,\n",
    "    choose_largest_cc,\n",
    "    get_real_communities,\n",
    "    set_weights,\n",
    "    evaluate_metric,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = load_features(\"./dataset/large_twitch_features.csv\")\n",
    "print(\"Loaded\", len(features.index), \"nodes\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove unused features and clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_remove = [\"OTHER\"]\n",
    "features = remove_features(features, features_to_remove)\n",
    "print(\"Kept\", len(features.index), \"nodes after removing\", features_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_remove = [\"EN\"]\n",
    "features = remove_features(features, features_to_remove)\n",
    "print(\"Kept\", len(features.index), \"nodes after removing\", features_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = load_edges(\"./dataset/large_twitch_edges.csv\", features)\n",
    "print(\"Loaded\", len(edges.index), \"edges\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Graph object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = create_graph(edges)\n",
    "\n",
    "print(\n",
    "    \"Created graph with\", G.number_of_nodes(), \"nodes and\", G.number_of_edges(), \"edges\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = choose_largest_cc(G)\n",
    "print(\n",
    "    \"Chose largest connected component with\",\n",
    "    G.number_of_nodes(),\n",
    "    \"nodes and\",\n",
    "    G.number_of_edges(),\n",
    "    \"edges\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the real communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_communities = get_real_communities(G, features)\n",
    "\n",
    "print(\"There are \", len(real_communities), \"communites with the folowing counts:\")\n",
    "for language, community in real_communities:\n",
    "    print(\"-\", language, len(community))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the different metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the tests to execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = [\n",
    "    (\"unitary\", metric_unitary, np.max),\n",
    "    (\"degree max\", metric_degree, np.max),\n",
    "    (\"degree mean\", metric_degree, np.mean),\n",
    "    (\"degree min\", metric_degree, np.min),\n",
    "    (\"degree diff\", metric_degree, lambda x: np.abs(x[0] - x[1])),\n",
    "    (\"degree max inverse\", metric_degree, lambda x: 1 / np.max(x)),\n",
    "    (\"degree_centrality max\", metric_degree_centrality, np.max),\n",
    "    (\"degree_centrality mean\", metric_degree_centrality, np.mean),\n",
    "    (\"degree_centrality min\", metric_degree_centrality, np.min),\n",
    "    (\"degree_centrality diff\", metric_degree_centrality, lambda x: np.abs(x[0] - x[1])),\n",
    "    (\n",
    "        \"degree_centrality max inverse\",\n",
    "        metric_degree_centrality,\n",
    "        lambda x: 1 / np.max(x),\n",
    "    ),\n",
    "    (\"eigenvector_centrality max\", metric_eigenvector_centrality, np.max),\n",
    "    (\"eigenvector_centrality mean\", metric_eigenvector_centrality, np.mean),\n",
    "    (\"eigenvector_centrality min\", metric_eigenvector_centrality, np.min),\n",
    "    (\n",
    "        \"eigenvector_centrality diff\",\n",
    "        metric_eigenvector_centrality,\n",
    "        lambda x: np.abs(x[0] - x[1]),\n",
    "    ),\n",
    "    (\n",
    "        \"eigenvector_centrality max inverse\",\n",
    "        metric_eigenvector_centrality,\n",
    "        lambda x: 1 / np.max(x),\n",
    "    ),\n",
    "    (\"pagerank max\", metric_pagerank, np.max),\n",
    "    (\"pagerank mean\", metric_pagerank, np.mean),\n",
    "    (\"pagerank min\", metric_pagerank, np.min),\n",
    "    (\"pagerank diff\", metric_pagerank, lambda x: np.abs(x[0] - x[1])),\n",
    "    (\"pagerank max inverse\", metric_pagerank, lambda x: 1 / np.max(x)),\n",
    "    (\"clustering max\", metric_clustering, np.max),\n",
    "    (\"clustering mean\", metric_clustering, np.mean),\n",
    "    (\"clustering min\", metric_clustering, np.min),\n",
    "    (\"clustering diff\", metric_clustering, lambda x: np.abs(x[0] - x[1])),\n",
    "    (\"clustering max inverse\", metric_clustering, lambda x: 1 / np.max(x)),\n",
    "    ## Too Long to calculate\n",
    "    # (\"closeness_centrality max\", metric_closeness_centrality, max),\n",
    "    # (\"betweeness_centrality max\", metric_betweeness_centrality, np.min),\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute the tests and save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test in tests:\n",
    "    result = {}\n",
    "    print(\"Evaluating\", test[0])\n",
    "    set_weights(G, test[1](G), test[2])\n",
    "    print(\"Generated weights\")\n",
    "    print(\"Evaluating...\")\n",
    "    scores = evaluate_metric(G, real_communities, 5)\n",
    "    result[\"mean\"] = np.mean(scores)\n",
    "    result[\"std\"] = np.std(scores)\n",
    "    result[\"min\"] = np.min(scores)\n",
    "    result[\"max\"] = np.max(scores)\n",
    "    result[\"scores\"] = scores\n",
    "    print(\"Saving\")\n",
    "    with open(f\"eval/{test[0]}.json\", \"w\") as f:\n",
    "        json.dump(result, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL",
   "language": "python",
   "name": "rl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
